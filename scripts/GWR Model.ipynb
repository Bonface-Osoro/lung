{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b58032-33ad-49a8-b8ee-844dfc271dfe",
   "metadata": {},
   "source": [
    "GWR (Geographically Weighted Regression) is a spatially varying coefficients model that explores how relationships between predictors (independent variables) and an outcome (dependent variable) change across space.\n",
    "\n",
    "In this project we want to investigate how mortality counts from pulmonary embolism changes over space (counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba9f722d-7dac-4022-993b-aebe8f75c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import statsmodels.api as sm\n",
    "from mgwr.gwr import GWR, MGWR\n",
    "from mgwr.sel_bw import Sel_BW\n",
    "from mgwr.utils import shift_colormap\n",
    "from shapely.geometry import Point\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "213224e9-4252-469f-91ea-7bb0e2705676",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "CONFIG = configparser.ConfigParser()\n",
    "CONFIG.read(os.path.join(BASE_DIR, 'script_config.ini'))\n",
    "\n",
    "BASE_PATH = os.path.abspath(os.path.join(os.getcwd(), '..', 'data'))\n",
    "\n",
    "DATA_RAW = os.path.join(BASE_PATH, 'raw')\n",
    "DATA_RESULTS = os.path.join(BASE_PATH, '..', 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa1926cb-887f-417f-9dec-b2a1801558d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(DATA_RESULTS, 'final', \n",
    "                   'pulmonary_air_quality_data.csv')\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df = df[df['geometry'].notna()]\n",
    "df = gpd.GeoDataFrame(df, geometry = \n",
    "     gpd.GeoSeries.from_wkt(df['geometry']), crs = 'EPSG:4326')\n",
    "\n",
    "df = df[['geometry', 'sex', 'race_recode3', 'age_cat', \n",
    "         'Daily Mean PM2.5 Concentration', 'Daily AQI Value', \n",
    "         'mort_per_100k']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1cfc9-ee72-460f-a292-78881574fada",
   "metadata": {},
   "source": [
    "However, GWR requires numeric predictors.\n",
    "We have to converg the categorical variables in our dataset into numeric dummy variables (one-hot encoding). But before we do that, we first have to handle the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ff5ec0-fd7c-47eb-b661-4cab20f687b2",
   "metadata": {},
   "source": [
    "We fill the missing values with the most frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66d212b9-adae-455a-837d-db3d2c22e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['sex', 'race_recode3', 'age_cat']\n",
    "for col in cat_cols:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629ecea3-094d-4e36-b1c2-5092f2d57af0",
   "metadata": {},
   "source": [
    "Next we encode the categorical columns with dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d2ee487-57e8-42d6-b842-df4bea36fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns = \n",
    "            [\"sex\", \"race_recode3\", \"age_cat\"], \n",
    "             dtype = int, drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e93c56-e222-4b98-b212-27f6de4fe214",
   "metadata": {},
   "source": [
    "Now, we define our dependent (y) variable i.e mort_per_100k and independent (x) variables ('Daily Mean PM2.5 Concentration', 'Daily AQI Value')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4dd93e8d-9928-4495-90d4-b8619613b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_encoded[\"mort_per_100k\"].values.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2019f48-eac1-4047-ae00-42a9718e42bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded[[\"Daily Mean PM2.5 Concentration\", \"Daily AQI Value\"] + \n",
    "    [col for col in df_encoded.columns if col.startswith((\"sex_\", \n",
    "    \"race_recode3_\", \"age_cat_\"))]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538d59fe-ca72-4ba2-93f5-a32597dd68c3",
   "metadata": {},
   "source": [
    "Now we extract individual (x, y) coordinates from the geometry column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45f804c8-6b59-4347-a2fc-452e4a4e0a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = df_encoded.geometry.x.values\n",
    "v = df_encoded.geometry.y.values\n",
    "coords = np.column_stack((u, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1196b78-57de-41bf-9f25-a3f687787e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(727225, 10)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c815ec4-23a5-49b0-b5f7-513bfba46bcf",
   "metadata": {},
   "source": [
    "We now fit the GWR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2dc86-90fd-4ceb-b20c-a8c3c04ad80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b91b529-6b76-4eb4-8fa9-03c256cd683a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '10 - 29 years'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- 2. Standardize predictors (important for numerical stability) ---\u001b[39;00m\n\u001b[32m      2\u001b[39m scaler = StandardScaler()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m X_scaled = scaler.fit_transform(X)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# --- 3. Bandwidth Selection ---\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# If your dataset is large (e.g. >100k), sample to speed this up\u001b[39;00m\n\u001b[32m      7\u001b[39m sample_size = \u001b[38;5;28mmin\u001b[39m(\u001b[32m5000\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/geosp/lib/python3.12/site-packages/sklearn/utils/_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = f(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs)\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/geosp/lib/python3.12/site-packages/sklearn/base.py:918\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    903\u001b[39m         warnings.warn(\n\u001b[32m    904\u001b[39m             (\n\u001b[32m    905\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    914\u001b[39m         )\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, **fit_params).transform(X)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/geosp/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:894\u001b[39m, in \u001b[36mStandardScaler.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    892\u001b[39m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    893\u001b[39m \u001b[38;5;28mself\u001b[39m._reset()\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partial_fit(X, y, sample_weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/geosp/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/geosp/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:930\u001b[39m, in \u001b[36mStandardScaler.partial_fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    898\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[32m    899\u001b[39m \n\u001b[32m    900\u001b[39m \u001b[33;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    927\u001b[39m \u001b[33;03m    Fitted scaler.\u001b[39;00m\n\u001b[32m    928\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    929\u001b[39m first_call = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mn_samples_seen_\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m X = validate_data(\n\u001b[32m    931\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    932\u001b[39m     X,\n\u001b[32m    933\u001b[39m     accept_sparse=(\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    934\u001b[39m     dtype=FLOAT_DTYPES,\n\u001b[32m    935\u001b[39m     ensure_all_finite=\u001b[33m\"\u001b[39m\u001b[33mallow-nan\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    936\u001b[39m     reset=first_call,\n\u001b[32m    937\u001b[39m )\n\u001b[32m    938\u001b[39m n_features = X.shape[\u001b[32m1\u001b[39m]\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/geosp/lib/python3.12/site-packages/sklearn/utils/validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = check_array(X, input_name=\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m, **check_params)\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/geosp/lib/python3.12/site-packages/sklearn/utils/validation.py:1055\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1053\u001b[39m         array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1054\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1055\u001b[39m         array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1058\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.format(array)\n\u001b[32m   1059\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/geosp/lib/python3.12/site-packages/sklearn/utils/_array_api.py:839\u001b[39m, in \u001b[36m_asarray_with_order\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    837\u001b[39m     array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m     array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    841\u001b[39m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray(array)\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: '10 - 29 years'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74058740-48a4-43e2-b1dd-abe79554916d",
   "metadata": {},
   "source": [
    "Now we extract the local parameter estimates (coefficients), RÂ² and residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4526108-7646-458e-8453-e3a5703a1852",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_coefs = results.params \n",
    "local_R2 = results.localR2  \n",
    "residuals = results.resid_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c931032-6cf8-42b9-bf67-3e2af4305dec",
   "metadata": {},
   "source": [
    "We then combine these arrays with our  original data and geometry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05865c8f-7fce-4c03-a7c5-08439ae45963",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_names = [\"Intercept\"] + list(\n",
    "    [\"Daily Mean PM2.5 Concentration\", \"Daily AQI Value\"]\n",
    "    + [col for col in df_encoded.columns if col.startswith((\n",
    "        \"sex_\", \"race_recode3_\", \"age_cat_\"))])\n",
    "\n",
    "coef_df = pd.DataFrame(local_coefs, columns = predictor_names)\n",
    "\n",
    "coef_df[\"local_R2\"] = local_R2\n",
    "coef_df[\"residuals\"] = residuals\n",
    "\n",
    "gwr_df = gpd.GeoDataFrame(pd.concat([df_encoded.reset_index(\n",
    "    drop = True), coef_df], axis = 1), geometry = df_encoded.geometry,\n",
    "                           crs = df_encoded.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08d3d2ed-b06e-4a0c-9c29-cbede0d1fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_out = os.path.join(DATA_RESULTS, 'final')\n",
    "\n",
    "filename = 'GWR_results.csv'\n",
    "path_out = os.path.join(folder_out, filename)\n",
    "gwr_df.to_csv(path_out, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf7d4e-b706-49b9-bb51-1872ab3f3af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
